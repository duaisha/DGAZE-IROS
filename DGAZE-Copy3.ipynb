{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DGAZE: Driver Gaze Mapping on the Road\n",
    "\n",
    "driver wise split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "# # The GPU id to use, usually either \"0\" or \"1\"\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from load_dataset import *\n",
    "from random import shuffle\n",
    "\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.regularizers import l2\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Input, Merge, Dropout\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.regularizers import l1\n",
    "from keras.layers import BatchNormalization\n",
    "from keras.optimizers import SGD, Adam, Adamax\n",
    "\n",
    "from keras.models import model_from_yaml\n",
    "import copy\n",
    "import h5py\n",
    "from keras.callbacks import Callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Utils functions\n",
    "\n",
    "## Metadata\n",
    "def get_metadata(__dict):\n",
    "    keys = []\n",
    "    for key, values in __dict.items():\n",
    "        keys.append(key)\n",
    "    return __dict, keys\n",
    "\n",
    "\n",
    "def print_metadata(driver_data, metakeys):\n",
    "    drivers_dict, drivers = get_metadata(driver_data)\n",
    "    seq_dict, sequences = get_metadata(drivers_dict[drivers[0]])\n",
    "    features_dict, features = get_metadata(seq_dict[sequences[0]])\n",
    "    \n",
    "    if 'drivers' in metakeys:\n",
    "        print(\"List of Drivers: \\n {}\\n\".format(drivers))\n",
    "    if 'sequences' in metakeys:\n",
    "        print(\"List of Sequences: \\n {}\\n\".format(sequences))\n",
    "    if 'features' in metakeys:\n",
    "        print(\"List of Features: \\n {}\\n\".format(features))\n",
    "        \n",
    "        \n",
    "def get_dgaze_frames_count(driver_data, drivers):\n",
    "    frames_count = 0\n",
    "    for driver in drivers:\n",
    "        data = driver_data[driver]\n",
    "        frames_count += data['frames_count']\n",
    "        print(\"Frames count for driver {} is {}\".format(driver, data['frames_count']))\n",
    "        \n",
    "    print(\"\\nTotal frames in DGAZE dataset is {}\".format(frames_count))\n",
    "\n",
    "# Split the dataset driver wise and points wise\n",
    "def split_driver_data(drivers, dsplit):\n",
    "    \"\"\"\n",
    "    Split the data into train-val and test based on number of drivers \n",
    "    dsplit = [driver_train_val, driver_test]\n",
    "    \n",
    "    Split the data into train, val and test based on number of unique points \n",
    "    gp_split = [gaze_point_train, gaze_point_val, gaze_point_test]\n",
    "    \"\"\"\n",
    "    ## Split based on drivers\n",
    "    drivers_train = drivers[:dsplit[0]]\n",
    "    drivers_val = drivers[dsplit[0]:dsplit[0]+dsplit[1]]\n",
    "    drivers_test = drivers[dsplit[0]+dsplit[1]:dsplit[0]+dsplit[1]+dsplit[2]]\n",
    "    \n",
    "    \n",
    "    return drivers_train, drivers_val, drivers_test\n",
    "\n",
    "# Split the dataset driver wise and points wise\n",
    "def split_data(drivers, sequences, dsplit, gp_split):\n",
    "    \"\"\"\n",
    "    Split the data into train-val and test based on number of drivers \n",
    "    dsplit = [driver_train_val, driver_test]\n",
    "    \n",
    "    Split the data into train, val and test based on number of unique points \n",
    "    gp_split = [gaze_point_train, gaze_point_val, gaze_point_test]\n",
    "    \"\"\"\n",
    "    ## Split based on drivers\n",
    "    drivers_train_val = drivers[:dsplit[0]]\n",
    "    drivers_test = drivers[dsplit[0]:dsplit[0]+dsplit[1]]\n",
    "\n",
    "    ## Split based on points\n",
    "    seq_range = np.arange(0,sequences)\n",
    "    shuffle(seq_range)\n",
    "    points_train = seq_range[:gp_split[0]]\n",
    "    points_val = seq_range[gp_split[0]:gp_split[0]+gp_split[1]]\n",
    "    points_test = seq_range[gp_split[0]+gp_split[1]:gp_split[0]+gp_split[1]+gp_split[2]]\n",
    "    \n",
    "    return drivers_train_val, drivers_test, points_train, points_val, points_test\n",
    "  \n",
    "    \n",
    "def load_data(driver_data, driver, points):\n",
    "    gaze_point = None\n",
    "    left_eye = None\n",
    "    right_eye = None\n",
    "    headpose_pupil = None\n",
    "    face_location = None\n",
    "    \n",
    "   \n",
    "    for ix in tqdm((points), position=0, leave=True):\n",
    " \n",
    "        seq = \"\".join(['seq',str(ix+1)]) \n",
    "        \n",
    "        if seq in driver_data[driver]:\n",
    "            data = driver_data[driver][\"\".join(['seq',str(ix+1)])]\n",
    "        \n",
    "            if gaze_point is None:\n",
    "                gaze_point = data['gaze_point']\n",
    "                left_eye = data['left_eye']\n",
    "                right_eye = data['right_eye']\n",
    "                headpose_pupil = data['headpose_pupil']\n",
    "                face_location = data['face_location']\n",
    "            else:\n",
    "                gaze_point = np.concatenate((gaze_point, data['gaze_point']),axis=0)\n",
    "                left_eye = np.concatenate((left_eye, data['left_eye']),axis=0)\n",
    "                right_eye = np.concatenate((right_eye, data['right_eye']),axis=0)\n",
    "                headpose_pupil = np.concatenate((headpose_pupil, data['headpose_pupil']),axis=0)\n",
    "                face_location = np.concatenate((face_location, data['face_location']),axis=0)\n",
    "    return left_eye, right_eye, headpose_pupil, face_location, gaze_point\n",
    "\n",
    "\n",
    "def dataset(drivers, points):\n",
    "    dgaze_left_eye = None\n",
    "    dgaze_right_eye = None\n",
    "    dgaze_headpose_pupil = None\n",
    "    dgaze_face_location = None\n",
    "    dgaze_gaze_point = None\n",
    "\n",
    "    for driver in tqdm((drivers), position=0, leave=True):\n",
    "        left_eye, right_eye, headpose_pupil, face_location, gaze_point = load_data(driver_data, driver, points)\n",
    "\n",
    "        if dgaze_left_eye is None:\n",
    "            dgaze_left_eye = left_eye\n",
    "            dgaze_right_eye = right_eye\n",
    "            dgaze_headpose_pupil = headpose_pupil\n",
    "            dgaze_face_location = face_location\n",
    "            dgaze_gaze_point = gaze_point\n",
    "        else:\n",
    "            dgaze_left_eye = np.concatenate((dgaze_left_eye, left_eye),axis=0)\n",
    "            dgaze_right_eye = np.concatenate((dgaze_right_eye, right_eye),axis=0)\n",
    "            dgaze_headpose_pupil = np.concatenate((dgaze_headpose_pupil, headpose_pupil),axis=0)\n",
    "            dgaze_face_location = np.concatenate((dgaze_face_location, face_location),axis=0)\n",
    "            dgaze_gaze_point = np.concatenate((dgaze_gaze_point, gaze_point),axis=0)\n",
    "\n",
    "    return dgaze_left_eye, dgaze_right_eye, dgaze_headpose_pupil, dgaze_face_location, dgaze_gaze_point\n",
    "\n",
    "def save_model(model_name, model):\n",
    "    # serialize model to YAML\n",
    "    model_yaml = model.to_yaml()\n",
    "    with open(model_name + '.yaml', \"w\") as yaml_file:\n",
    "        yaml_file.write(model_yaml)\n",
    "    # serialize weights to HDF5\n",
    "    model.save_weights(model_name + \".h5\")\n",
    "    print(\"Saved model to disk\")\n",
    "    \n",
    "def load_model(model_name):\n",
    "    yaml_file = open(model_name + '.yaml', 'r')\n",
    "    loaded_model_yaml = yaml_file.read()\n",
    "    yaml_file.close()\n",
    "    loaded_model = model_from_yaml(loaded_model_yaml)\n",
    "    # load weights into new model\n",
    "    loaded_model.load_weights(model_name + \".h5\")\n",
    "    print(\"Loaded model from disk\")\n",
    "    return loaded_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:05<00:00,  3.29it/s]\n"
     ]
    }
   ],
   "source": [
    "data_path = '/ssd_scratch/cvit/isha/eye_gaze_mapping/DGM_final2/dataset_samples_callibrated/'\n",
    "drivers = os.listdir(data_path)\n",
    "ndrivers = len(drivers)\n",
    "frames_per_seq = 50\n",
    "sequences = 112\n",
    "\n",
    "driver_data = get_data(data_path, drivers, sequences, frames_per_seq)\n",
    "\n",
    "#print_metadata(driver_data, ['features'])\n",
    "#get_dgaze_frames_count(driver_data, drivers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dsplit = [14,3,3]\n",
    "drivers_train, drivers_val, drivers_test = split_driver_data(drivers, dsplit)\n",
    "print(drivers_train, drivers_val, drivers_test )\n",
    "\n",
    "points_train = np.arange(0,sequences)\n",
    "points_val = np.arange(0,sequences)\n",
    "points_test = np.arange(0,sequences)\n",
    "\n",
    "print(\"For train points\")\n",
    "train_left_eye, train_right_eye, train_headpose_pupil, train_face_location, train_gaze_point = dataset(drivers_train, points_train)\n",
    "\n",
    "print(\"For val points\")\n",
    "val_left_eye, val_right_eye, val_headpose_pupil, val_face_location, val_gaze_point = dataset(drivers_val, points_val)\n",
    "\n",
    "print(\"For test points\")\n",
    "test_left_eye, test_right_eye, test_headpose_pupil, test_face_location, test_gaze_point =dataset(drivers_test, points_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(156959, 36, 60, 3) (156959, 36, 60, 3) (156959, 11) (156959, 4) (156959, 6)\n",
      "(35907, 36, 60, 3) (35907, 36, 60, 3) (35907, 11) (35907, 4) (35907, 6)\n",
      "(34312, 36, 60, 3) (34312, 36, 60, 3) (34312, 11) (34312, 4) (34312, 6)\n"
     ]
    }
   ],
   "source": [
    "print(train_left_eye.shape, train_right_eye.shape, train_headpose_pupil.shape, train_face_location.shape, train_gaze_point.shape \n",
    ")\n",
    "print(val_left_eye.shape, val_right_eye.shape, val_headpose_pupil.shape, val_face_location.shape, val_gaze_point.shape)\n",
    "print(test_left_eye.shape, test_right_eye.shape, test_headpose_pupil.shape, test_face_location.shape, test_gaze_point.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_range = np.arange(0, train_gaze_point.shape[0])\n",
    "val_range = np.arange(0, val_gaze_point.shape[0])\n",
    "test_range = np.arange(0, test_gaze_point.shape[0])\n",
    "\n",
    "shuffle(train_range)\n",
    "shuffle(val_range)\n",
    "shuffle(test_range)\n",
    "\n",
    "train_left_eye, train_right_eye, train_headpose_pupil, train_face_location, train_gaze_point = \\\n",
    "    train_left_eye[train_range], train_right_eye[train_range], train_headpose_pupil[train_range], train_face_location[train_range], train_gaze_point[train_range]\n",
    "    \n",
    "val_left_eye, val_right_eye, val_headpose_pupil, val_face_location, val_gaze_point = \\\n",
    "    val_left_eye[val_range], val_right_eye[val_range], val_headpose_pupil[val_range], val_face_location[val_range], val_gaze_point[val_range]\n",
    "    \n",
    "test_left_eye, test_right_eye, test_headpose_pupil, test_face_location, test_gaze_point = \\\n",
    "    test_left_eye[test_range], test_right_eye[test_range], test_headpose_pupil[test_range], test_face_location[test_range], test_gaze_point[test_range]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "\n",
    "def write_h5(left_eye, right_eye, headpose_pupil, face_location, gaze_point, filename):\n",
    "    hf = h5py.File(filename, 'w')\n",
    "    hf.create_dataset('left_eye', data=left_eye)\n",
    "    hf.create_dataset('right_eye', data=right_eye)\n",
    "    hf.create_dataset('headpose_pupil', data=headpose_pupil)\n",
    "    hf.create_dataset('face_location', data=face_location)\n",
    "    hf.create_dataset('gaze_point', data=gaze_point.astype(int))\n",
    "    hf.close()\n",
    "    \n",
    "write_h5(train_left_eye, train_right_eye, train_headpose_pupil, train_face_location, train_gaze_point, 'data/train.h5')\n",
    "write_h5(val_left_eye, val_right_eye, val_headpose_pupil, val_face_location, val_gaze_point, 'data/val.h5')\n",
    "write_h5(test_left_eye, test_right_eye, test_headpose_pupil, test_face_location, test_gaze_point, 'data/test.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_h5(filename):\n",
    "    hf = h5py.File(filename, 'r')\n",
    "    left_eye = np.array(hf.get('left_eye'))\n",
    "    right_eye = np.array(hf.get('right_eye'))\n",
    "    headpose_pupil = np.array(hf.get('headpose_pupil'))\n",
    "    face_location = np.array(hf.get('face_location'))\n",
    "    gaze_point = np.array(hf.get('gaze_point'))\n",
    "    hf.close()\n",
    "    \n",
    "    return left_eye, right_eye, headpose_pupil, face_location, gaze_point,\n",
    "    \n",
    "train_left_eye, train_right_eye, train_headpose_pupil, train_face_location, train_gaze_point = read_h5('data/train.h5')\n",
    "val_left_eye, val_right_eye, val_headpose_pupil, val_face_location, val_gaze_point= read_h5('data/val.h5')\n",
    "test_left_eye, test_right_eye, test_headpose_pupil, test_face_location, test_gaze_point= read_h5('data/test.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### I-DGAZE: Predicting driver gaze on road"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 32, 56, 50)        3800      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 16, 28, 50)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 16, 28, 50)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 12, 24, 50)        62550     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 6, 12, 50)         0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 6, 12, 50)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 3600)              0         \n",
      "=================================================================\n",
      "Total params: 66,350\n",
      "Trainable params: 66,350\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "from keras.regularizers import l2\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(50, kernel_size=(5,5),activation='relu',input_shape=(36,60,3)))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "#model.add(Conv2D(50, (3, 3), activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Conv2D(50, (5,5), activation='relu',kernel_regularizer=l2(0.01), bias_regularizer=l2(0.01)))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Flatten())\n",
    "inputs = Input(shape=(10,))\n",
    "#model2= model\n",
    "\n",
    "model3 = Sequential()\n",
    "model3.add(Dense(16, activation ='relu', input_dim=(14)))\n",
    "\n",
    "model2 = Sequential()\n",
    "model2.add(Merge([model, model3], mode = 'concat'))\n",
    "\n",
    "model2.add(Dense(512, activation='relu', kernel_regularizer=l2(0.01), bias_regularizer=l2(0.01)))\n",
    "#model2.add(Dense(500))\n",
    "model2.add(Dense(2))\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_face_features = np.concatenate((train_headpose_pupil[:,[1,2,3,4,5,6,7,8,9,10]],train_face_location[:]), axis =1)\n",
    "val_face_features = np.concatenate((val_headpose_pupil[:,[1,2,3,4,5,6,7,8,9,10]],val_face_location[:]), axis =1)\n",
    "test_face_features = np.concatenate((test_headpose_pupil[:,[1,2,3,4,5,6,7,8,9,10]],test_face_location[:]), axis =1)\n",
    "\n",
    "from sklearn import preprocessing\n",
    "train_face_features = np.concatenate((train_headpose_pupil[:,[1,2,3,4,5,6,7,8,9,10]],train_face_location[:]), axis =1)\n",
    "val_face_features = np.concatenate((val_headpose_pupil[:,[1,2,3,4,5,6,7,8,9,10]],val_face_location[:]), axis =1)\n",
    "test_face_features = np.concatenate((test_headpose_pupil[:,[1,2,3,4,5,6,7,8,9,10]],test_face_location[:]), axis =1)\n",
    "\n",
    "mm_scaler = preprocessing.MinMaxScaler()\n",
    "train_face_features = mm_scaler.fit_transform(train_face_features)\n",
    "val_face_features = mm_scaler.transform(val_face_features)\n",
    "test_face_features = mm_scaler.transform(test_face_features)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 156959 samples, validate on 35907 samples\n",
      "Epoch 1/100\n",
      "156959/156959 [==============================] - 30s 192us/step - loss: 156.3285 - val_loss: 222.4719\n",
      "Epoch 2/100\n",
      "156959/156959 [==============================] - 30s 189us/step - loss: 156.7079 - val_loss: 223.0189\n",
      "Epoch 3/100\n",
      "156959/156959 [==============================] - 29s 188us/step - loss: 156.9153 - val_loss: 228.2428\n",
      "Epoch 4/100\n",
      "156959/156959 [==============================] - 30s 189us/step - loss: 156.9882 - val_loss: 222.5842\n",
      "Epoch 5/100\n",
      "156959/156959 [==============================] - 30s 188us/step - loss: 156.8222 - val_loss: 218.1615\n",
      "Epoch 6/100\n",
      "156959/156959 [==============================] - 30s 189us/step - loss: 156.8853 - val_loss: 222.2842\n",
      "Epoch 7/100\n",
      "156959/156959 [==============================] - 30s 189us/step - loss: 156.8249 - val_loss: 227.3562\n",
      "Epoch 8/100\n",
      "156959/156959 [==============================] - 30s 188us/step - loss: 156.9886 - val_loss: 228.3710\n",
      "Epoch 9/100\n",
      "156959/156959 [==============================] - 30s 190us/step - loss: 156.9180 - val_loss: 222.5537\n",
      "Epoch 10/100\n",
      "156959/156959 [==============================] - 30s 188us/step - loss: 156.6910 - val_loss: 223.1346\n",
      "Epoch 11/100\n",
      "156959/156959 [==============================] - 30s 190us/step - loss: 156.8748 - val_loss: 220.1891\n",
      "Epoch 12/100\n",
      "156959/156959 [==============================] - 30s 189us/step - loss: 156.5607 - val_loss: 222.7241\n",
      "Epoch 13/100\n",
      "156959/156959 [==============================] - 30s 190us/step - loss: 156.8392 - val_loss: 224.9240\n",
      "Epoch 14/100\n",
      "156959/156959 [==============================] - 30s 189us/step - loss: 156.7620 - val_loss: 222.5633\n",
      "Epoch 15/100\n",
      "156959/156959 [==============================] - 30s 190us/step - loss: 156.8446 - val_loss: 223.1495\n",
      "Epoch 16/100\n",
      "156959/156959 [==============================] - 30s 189us/step - loss: 156.6268 - val_loss: 222.7617\n",
      "Epoch 17/100\n",
      "156959/156959 [==============================] - 30s 189us/step - loss: 156.2330 - val_loss: 225.8467\n",
      "Epoch 18/100\n",
      "156959/156959 [==============================] - 30s 190us/step - loss: 156.5596 - val_loss: 222.0204\n",
      "Epoch 19/100\n",
      "156959/156959 [==============================] - 30s 188us/step - loss: 156.8932 - val_loss: 217.6287\n",
      "Epoch 20/100\n",
      "156959/156959 [==============================] - 30s 190us/step - loss: 156.5591 - val_loss: 226.2605\n",
      "Epoch 21/100\n",
      "156959/156959 [==============================] - 30s 188us/step - loss: 156.4602 - val_loss: 229.4873\n",
      "Epoch 22/100\n",
      "156959/156959 [==============================] - 30s 190us/step - loss: 156.3968 - val_loss: 221.6540\n",
      "Epoch 23/100\n",
      "156959/156959 [==============================] - 30s 189us/step - loss: 156.3133 - val_loss: 224.8853\n",
      "Epoch 24/100\n",
      "156959/156959 [==============================] - 30s 190us/step - loss: 156.5241 - val_loss: 221.6126\n",
      "Epoch 25/100\n",
      "156959/156959 [==============================] - 30s 189us/step - loss: 156.3335 - val_loss: 219.2316\n",
      "Epoch 26/100\n",
      "156959/156959 [==============================] - 30s 189us/step - loss: 156.3051 - val_loss: 223.1515\n",
      "Epoch 27/100\n",
      "156959/156959 [==============================] - 30s 190us/step - loss: 156.5118 - val_loss: 218.6068\n",
      "Epoch 28/100\n",
      "156959/156959 [==============================] - 30s 188us/step - loss: 156.2669 - val_loss: 224.5472\n",
      "Epoch 29/100\n",
      "156959/156959 [==============================] - 30s 190us/step - loss: 156.1014 - val_loss: 220.4566\n",
      "Epoch 30/100\n",
      "156959/156959 [==============================] - 30s 188us/step - loss: 156.7064 - val_loss: 216.0476\n",
      "Epoch 31/100\n",
      "156959/156959 [==============================] - 30s 190us/step - loss: 156.1914 - val_loss: 224.6505\n",
      "Epoch 32/100\n",
      "156959/156959 [==============================] - 30s 189us/step - loss: 156.3052 - val_loss: 222.8200\n",
      "Epoch 33/100\n",
      "156959/156959 [==============================] - 30s 189us/step - loss: 156.1295 - val_loss: 221.1631\n",
      "Epoch 34/100\n",
      "156959/156959 [==============================] - 30s 189us/step - loss: 156.6606 - val_loss: 221.8249\n",
      "Epoch 35/100\n",
      "156959/156959 [==============================] - 30s 189us/step - loss: 156.6885 - val_loss: 226.4254\n",
      "Epoch 36/100\n",
      "156959/156959 [==============================] - 30s 190us/step - loss: 156.1918 - val_loss: 216.4164\n",
      "Epoch 37/100\n",
      "156959/156959 [==============================] - 30s 188us/step - loss: 156.2793 - val_loss: 224.4407\n",
      "Epoch 38/100\n",
      "156959/156959 [==============================] - 30s 190us/step - loss: 155.9004 - val_loss: 222.3409\n",
      "Epoch 39/100\n",
      "156959/156959 [==============================] - 30s 189us/step - loss: 156.0179 - val_loss: 222.1628\n",
      "Epoch 40/100\n",
      "156959/156959 [==============================] - 30s 190us/step - loss: 156.0611 - val_loss: 221.3038\n",
      "Epoch 41/100\n",
      "156959/156959 [==============================] - 30s 189us/step - loss: 156.1319 - val_loss: 221.3816\n",
      "Epoch 42/100\n",
      "156959/156959 [==============================] - 30s 190us/step - loss: 156.0782 - val_loss: 220.3729\n",
      "Epoch 43/100\n",
      "156959/156959 [==============================] - 30s 189us/step - loss: 156.1974 - val_loss: 219.3973\n",
      "Epoch 44/100\n",
      "156959/156959 [==============================] - 30s 189us/step - loss: 155.9929 - val_loss: 223.0519\n",
      "Epoch 45/100\n",
      "156959/156959 [==============================] - 30s 190us/step - loss: 155.8464 - val_loss: 228.6769\n",
      "Epoch 46/100\n",
      "156959/156959 [==============================] - 30s 189us/step - loss: 156.1008 - val_loss: 218.0489\n",
      "Epoch 47/100\n",
      "156959/156959 [==============================] - 30s 190us/step - loss: 156.1891 - val_loss: 225.3434\n",
      "Epoch 48/100\n",
      "156959/156959 [==============================] - 30s 188us/step - loss: 155.8038 - val_loss: 225.3714\n",
      "Epoch 49/100\n",
      "156959/156959 [==============================] - 30s 190us/step - loss: 155.9955 - val_loss: 225.5344\n",
      "Epoch 50/100\n",
      "156959/156959 [==============================] - 30s 189us/step - loss: 156.0566 - val_loss: 222.5641\n",
      "Epoch 51/100\n",
      "156959/156959 [==============================] - 30s 189us/step - loss: 155.8627 - val_loss: 227.8494\n",
      "Epoch 52/100\n",
      "156959/156959 [==============================] - 30s 189us/step - loss: 155.5577 - val_loss: 224.6847\n",
      "Epoch 53/100\n",
      "156959/156959 [==============================] - 30s 189us/step - loss: 155.6249 - val_loss: 226.8966\n",
      "Epoch 54/100\n",
      "156959/156959 [==============================] - 30s 190us/step - loss: 155.7655 - val_loss: 227.9537\n",
      "Epoch 55/100\n",
      "156959/156959 [==============================] - 30s 188us/step - loss: 155.9233 - val_loss: 221.3301\n",
      "Epoch 56/100\n",
      "156959/156959 [==============================] - 30s 190us/step - loss: 156.0456 - val_loss: 225.9065\n",
      "Epoch 57/100\n",
      "156959/156959 [==============================] - 30s 189us/step - loss: 155.9744 - val_loss: 224.6600\n",
      "Epoch 58/100\n",
      "156959/156959 [==============================] - 30s 190us/step - loss: 155.9217 - val_loss: 223.2506\n",
      "Epoch 59/100\n",
      "156959/156959 [==============================] - 30s 189us/step - loss: 155.9358 - val_loss: 230.7361\n",
      "Epoch 60/100\n",
      "156959/156959 [==============================] - 30s 189us/step - loss: 155.6116 - val_loss: 227.9187\n",
      "Epoch 61/100\n",
      "156959/156959 [==============================] - 30s 190us/step - loss: 155.8849 - val_loss: 229.5886\n",
      "Epoch 62/100\n",
      "156959/156959 [==============================] - 30s 189us/step - loss: 155.9195 - val_loss: 224.7577\n",
      "Epoch 63/100\n",
      "156959/156959 [==============================] - 30s 190us/step - loss: 155.6407 - val_loss: 219.3010\n",
      "Epoch 64/100\n",
      "156959/156959 [==============================] - 30s 189us/step - loss: 155.5242 - val_loss: 225.2335\n",
      "Epoch 65/100\n",
      "156959/156959 [==============================] - 30s 190us/step - loss: 155.7999 - val_loss: 219.8907\n",
      "Epoch 66/100\n",
      "156959/156959 [==============================] - 30s 189us/step - loss: 155.5145 - val_loss: 224.0227\n",
      "Epoch 67/100\n",
      "156959/156959 [==============================] - 30s 190us/step - loss: 155.8141 - val_loss: 226.9463\n",
      "Epoch 68/100\n",
      "156959/156959 [==============================] - 30s 189us/step - loss: 155.7802 - val_loss: 221.9265\n",
      "Epoch 69/100\n",
      "156959/156959 [==============================] - 30s 190us/step - loss: 155.6666 - val_loss: 228.1090\n",
      "Epoch 70/100\n",
      "156959/156959 [==============================] - 30s 189us/step - loss: 155.9027 - val_loss: 222.6593\n",
      "Epoch 71/100\n",
      "156959/156959 [==============================] - 30s 189us/step - loss: 155.7659 - val_loss: 225.0242\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 72/100\n",
      "156959/156959 [==============================] - 30s 190us/step - loss: 155.5696 - val_loss: 229.1204\n",
      "Epoch 73/100\n",
      "156959/156959 [==============================] - 30s 189us/step - loss: 155.4321 - val_loss: 224.4596\n",
      "Epoch 74/100\n",
      "156959/156959 [==============================] - 30s 190us/step - loss: 155.4451 - val_loss: 227.7656\n",
      "Epoch 75/100\n",
      "156959/156959 [==============================] - 30s 189us/step - loss: 155.7132 - val_loss: 223.1865\n",
      "Epoch 76/100\n",
      "156959/156959 [==============================] - 30s 190us/step - loss: 155.3272 - val_loss: 231.0766\n",
      "Epoch 77/100\n",
      "156959/156959 [==============================] - 30s 189us/step - loss: 155.3989 - val_loss: 230.9370\n",
      "Epoch 78/100\n",
      "156959/156959 [==============================] - 30s 190us/step - loss: 155.7976 - val_loss: 222.0633\n",
      "Epoch 79/100\n",
      "156959/156959 [==============================] - 30s 189us/step - loss: 155.6016 - val_loss: 226.6536\n",
      "Epoch 80/100\n",
      "156959/156959 [==============================] - 30s 189us/step - loss: 155.4191 - val_loss: 223.3079\n",
      "Epoch 81/100\n",
      "156959/156959 [==============================] - 30s 190us/step - loss: 155.5550 - val_loss: 220.2855\n",
      "Epoch 82/100\n",
      "156959/156959 [==============================] - 30s 189us/step - loss: 155.2221 - val_loss: 221.3226\n",
      "Epoch 83/100\n",
      "156959/156959 [==============================] - 30s 190us/step - loss: 155.5304 - val_loss: 223.9701\n",
      "Epoch 84/100\n",
      "156959/156959 [==============================] - 30s 189us/step - loss: 155.3603 - val_loss: 226.8716\n",
      "Epoch 85/100\n",
      "156959/156959 [==============================] - 30s 190us/step - loss: 155.4058 - val_loss: 224.0911\n",
      "Epoch 86/100\n",
      "156959/156959 [==============================] - 30s 189us/step - loss: 155.4602 - val_loss: 220.0187\n",
      "Epoch 87/100\n",
      "156959/156959 [==============================] - 30s 190us/step - loss: 155.4603 - val_loss: 222.9399\n",
      "Epoch 88/100\n",
      "156959/156959 [==============================] - 30s 189us/step - loss: 155.3062 - val_loss: 224.8775\n",
      "Epoch 89/100\n",
      "156959/156959 [==============================] - 30s 189us/step - loss: 155.1086 - val_loss: 218.2079\n",
      "Epoch 90/100\n",
      "156959/156959 [==============================] - 30s 190us/step - loss: 155.5098 - val_loss: 226.1407\n",
      "Epoch 91/100\n",
      "156959/156959 [==============================] - 30s 189us/step - loss: 155.1673 - val_loss: 222.7051\n",
      "Epoch 92/100\n",
      "156959/156959 [==============================] - 30s 190us/step - loss: 155.3972 - val_loss: 227.8671\n",
      "Epoch 93/100\n",
      "156959/156959 [==============================] - 30s 189us/step - loss: 155.3755 - val_loss: 222.8075\n",
      "Epoch 94/100\n",
      "156959/156959 [==============================] - 30s 190us/step - loss: 155.4640 - val_loss: 227.0345\n",
      "Epoch 95/100\n",
      "156959/156959 [==============================] - 30s 189us/step - loss: 155.4143 - val_loss: 217.1289\n",
      "Epoch 96/100\n",
      "156959/156959 [==============================] - 30s 190us/step - loss: 155.1753 - val_loss: 226.5391\n",
      "Epoch 97/100\n",
      "156959/156959 [==============================] - 30s 189us/step - loss: 155.0613 - val_loss: 218.4888\n",
      "Epoch 98/100\n",
      "156959/156959 [==============================] - 30s 189us/step - loss: 155.2947 - val_loss: 225.0179\n",
      "Epoch 99/100\n",
      "156959/156959 [==============================] - 30s 190us/step - loss: 155.1570 - val_loss: 221.3982\n",
      "Epoch 100/100\n",
      "156959/156959 [==============================] - 30s 189us/step - loss: 155.0518 - val_loss: 222.4059\n",
      "dict_keys(['val_loss', 'loss'])\n"
     ]
    }
   ],
   "source": [
    "opt = Adam(lr=0.000001)\n",
    "mc = keras.callbacks.ModelCheckpoint('weights/weights{epoch:04d}.h5', \n",
    "                                     save_weights_only=True, period=1)\n",
    "\n",
    "\n",
    "model2.compile(loss='mae', optimizer='adam')\n",
    "earlystopping = keras.callbacks.EarlyStopping(monitor = 'val_loss',min_delta = 1, patience =3, verbose =0, mode ='auto')\n",
    "\n",
    "history = model2.fit([train_left_eye, train_face_features], train_gaze_point[:,:2], \\\n",
    "                      validation_data=([val_left_eye, val_face_features],val_gaze_point[:,:2]),\\\n",
    "                     epochs=100, batch_size=40, callbacks=[mc], verbose=1, shuffle= True)\n",
    "print(history.history.keys())\n",
    "\n",
    "# save_model(model_name, model3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gaze_error(left_eye, face_features, gaze_point):\n",
    "    scores = model2.evaluate([left_eye, face_features], gaze_point)\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "156959/156959 [==============================] - 10s 64us/step\n",
      "35907/35907 [==============================] - 2s 63us/step\n",
      "34312/34312 [==============================] - 2s 63us/step\n",
      "Train Error ==>  153.84305066577943\n",
      "Val Error ==>  222.40589565120186\n",
      "Test Error ==>  214.8826693648029\n"
     ]
    }
   ],
   "source": [
    "train_error = gaze_error(train_left_eye, train_face_features, train_gaze_point[:,:2])\n",
    "val_error = gaze_error(val_left_eye, val_face_features, val_gaze_point[:,:2])\n",
    "test_error = gaze_error(test_left_eye, test_face_features, test_gaze_point[:,:2])\n",
    "    \n",
    "print(\"Train Error ==> \", train_error)\n",
    "print(\"Val Error ==> \",  val_error)\n",
    "print(\"Test Error ==> \" ,test_error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_out(driver, train_points, test_points, model, frame_no):\n",
    "\n",
    "    driver_frame_out = None\n",
    "\n",
    "    for tp in points_test:\n",
    "        road_video = data_path + drivers[0] + \"/original_road_view/sample_\" +str(tp+1)+\".avi\"\n",
    "        driver_video = data_path + drivers[0] + \"/driver_view/sample_\" +str(tp+1)+\".avi\"\n",
    "\n",
    "        if \"\".join(['seq',str(tp+1)]) in driver_data[driver[0]]:\n",
    "            tr_left_eye, tr_right_eye, tr_headpose_pupil, tr_face_location, tr_gaze_point = dataset(driver, train_points)\n",
    "            te_data = driver_data[driver[0]][\"\".join(['seq',str(tp+1)])]\n",
    "\n",
    "            gaze_point = te_data['gaze_point']\n",
    "            left_eye = te_data['left_eye']\n",
    "            right_eye = te_data['right_eye']\n",
    "            headpose_pupil = te_data['headpose_pupil']\n",
    "            face_location = te_data['face_location']\n",
    "            face_features = np.concatenate((headpose_pupil[:,[1,2,3,4,5,6,7,9,10]],face_location[:]), axis =1)\n",
    "            tr_face_features = np.concatenate((tr_headpose_pupil[:,[1,2,3,4,5,6,7,9,10]],tr_face_location[:]), axis =1)\n",
    "\n",
    "            model = load_model(model_name)\n",
    "            \n",
    "            \n",
    "            pred_bef_calib = model.predict([left_eye, face_features])\n",
    "\n",
    "            model.fit([tr_left_eye, tr_face_features], tr_gaze_point[:,:2], \\\n",
    "                       validation_data=([left_eye, face_features],gaze_point[:,:2]),\\\n",
    "                             epochs=20, batch_size=8, callbacks=[earlystopping], verbose=1, shuffle= True)\n",
    "\n",
    "            pred_after_calib = model.predict([left_eye, face_features])\n",
    "\n",
    "            road_vid = cv2.VideoCapture(road_video)\n",
    "            driver_vid = cv2.VideoCapture(driver_video)\n",
    "\n",
    "            for i in range(0,frame_no):\n",
    "                ret,road_frame = road_vid.read()\n",
    "                ret1, driver_frame = driver_vid.read()\n",
    "\n",
    "            frame_gt = cv2.circle(road_frame,(gaze_point[frame_no,0], gaze_point[frame_no,1]), 70, (0,255,0), -1 )\n",
    "            frame_pred = cv2.circle(frame_gt,(pred_bef_calib[frame_no,0], pred_bef_calib[frame_no,1]), 70, (0,0,255), -1 )\n",
    "\n",
    "\n",
    "            frame_bef = road_frame.copy()\n",
    "            frame_after= road_frame.copy()\n",
    "            for i in range(0, gaze_point.shape[0]):\n",
    "                frame_bef = cv2.circle(frame_bef,(gaze_point[i,0], gaze_point[i,1]), 70, (0,255,0), -1 )    \n",
    "                frame_bef = cv2.circle(frame_bef,(pred_bef_calib[i,0], pred_bef_calib[i,1]), 70, (0,0,255), -1)  \n",
    "\n",
    "                frame_after = cv2.circle(frame_after,(gaze_point[i,0], gaze_point[i,1]), 70, (0,255,0), -1 )    \n",
    "                frame_after = cv2.circle(frame_after,(pred_after_calib[i,0], pred_after_calib[i,1]), 70, (0,0,255), -1)  \n",
    "\n",
    "\n",
    "            frame_out = driver_frame\n",
    "            frame_out = np.concatenate((frame_out, frame_gt), axis =1)\n",
    "            frame_out = np.concatenate((frame_out, frame_pred), axis =1)\n",
    "            frame_out = np.concatenate((frame_out, frame_bef), axis =1)\n",
    "            frame_out = np.concatenate((frame_out, frame_after), axis =1)\n",
    "\n",
    "            if driver_frame_out is None:\n",
    "                driver_frame_out = frame_out\n",
    "            else:\n",
    "                driver_frame_out = np.concatenate((driver_frame_out, frame_out), axis =0)\n",
    "\n",
    "    return driver_frame_out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = [drivers_train_val[0]]\n",
    "train_points = np.arange(0,9)\n",
    "test_points = points_test\n",
    "model = model3\n",
    "frame_no = 25\n",
    "\n",
    "out = plot_out(driver, train_points, test_points, model, frame_no)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
